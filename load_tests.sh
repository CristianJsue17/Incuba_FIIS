#!/bin/bash

echo "ğŸ¯ PRUEBAS DE CARGA ESPECÃFICAS - INCUBAUNAS"
echo "============================================"
echo ""

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# FunciÃ³n para verificar que la aplicaciÃ³n estÃ© corriendo
check_app_running() {
    echo -e "${BLUE}ğŸ” VERIFICANDO QUE LA APLICACIÃ“N ESTÃ‰ CORRIENDO${NC}"
    echo "=============================================="
    
    if curl -s "http://localhost:3200" > /dev/null; then
        echo -e "${GREEN}âœ… AplicaciÃ³n corriendo en http://localhost:3200${NC}"
        echo ""
        return 0
    else
        echo -e "${RED}âŒ La aplicaciÃ³n no estÃ¡ corriendo${NC}"
        echo -e "${YELLOW}ğŸ’¡ Ejecuta: docker-compose up -d${NC}"
        echo ""
        return 1
    fi
}

# Test 1: MÃºltiples usuarios navegando simultÃ¡neamente
test_concurrent_users() {
    echo -e "${BLUE}ğŸ‘¥ TEST 1: USUARIOS CONCURRENTES NAVEGANDO${NC}"
    echo "=========================================="
    
    echo "ğŸš€ Simulando 20 usuarios navegando simultÃ¡neamente..."
    
    # Array de pÃ¡ginas principales de IncubaUNAS
    pages=(
        "http://localhost:3200/"
        "http://localhost:3200/programas"
        "http://localhost:3200/eventos" 
        "http://localhost:3200/servicios"
        "http://localhost:3200/mentores"
    )
    
    # Monitorear Docker durante la prueba
    echo "ğŸ“Š Iniciando monitoreo de recursos..."
    docker stats incuba-fiis-web --no-stream --format "table {{.CPUPerc}}\t{{.MemUsage}}" > /tmp/before_load.txt
    
    echo "â±ï¸ Ejecutando carga de usuarios concurrentes..."
    
    # Crear mÃºltiples requests concurrentes
    for i in {1..20}; do
        page=${pages[$((RANDOM % ${#pages[@]}))]}
        (
            start_time=$(date +%s%N)
            curl -s "$page" > /dev/null 2>&1
            end_time=$(date +%s%N)
            duration=$(( (end_time - start_time) / 1000000 ))
            echo "Usuario $i: ${duration}ms - $page"
        ) &
        
        # PequeÃ±o delay para simular llegada gradual
        sleep 0.1
    done
    
    # Esperar que terminen todas las requests
    wait
    
    # Monitorear Docker despuÃ©s de la carga
    docker stats incuba-fiis-web --no-stream --format "table {{.CPUPerc}}\t{{.MemUsage}}" > /tmp/after_load.txt
    
    echo ""
    echo "ğŸ“Š EstadÃ­sticas de recursos:"
    echo "Antes: $(cat /tmp/before_load.txt)"
    echo "DespuÃ©s: $(cat /tmp/after_load.txt)"
    echo ""
}

# Test 2: Formularios pesados (registro de eventos/programas)
test_heavy_forms() {
    echo -e "${BLUE}ğŸ“ TEST 2: FORMULARIOS PESADOS${NC}"
    echo "=============================="
    
    echo "ğŸ§ª Simulando envÃ­o de mÃºltiples formularios..."
    
    # Datos de prueba para formularios
    form_data=(
        "name=Evento+Test+1&description=Descripcion+larga+del+evento"
        "name=Programa+Test+2&type=incubacion&duration=6+meses"
        "name=Testimonio+Test+3&content=Un+testimonio+muy+largo"
    )
    
    for i in {1..10}; do
        data=${form_data[$((RANDOM % ${#form_data[@]}))]}
        (
            start_time=$(date +%s%N)
            # Simular POST request (ajusta la URL segÃºn tu aplicaciÃ³n)
            curl -s -X POST -d "$data" "http://localhost:3200/" > /dev/null 2>&1
            end_time=$(date +%s%N)
            duration=$(( (end_time - start_time) / 1000000 ))
            echo "Formulario $i: ${duration}ms"
        ) &
        
        sleep 0.2
    done
    
    wait
    echo ""
}

# Test 3: SimulaciÃ³n de exports masivos (PDF/Excel)
test_export_stress() {
    echo -e "${BLUE}ğŸ“Š TEST 3: EXPORTS MASIVOS${NC}"
    echo "=========================="
    
    echo "ğŸ—‚ï¸ Simulando mÃºltiples exports simultÃ¡neos..."
    
    # Simular requests de export (ajusta URLs segÃºn tu app)
    export_urls=(
        "http://localhost:3200/programas.pdf"
        "http://localhost:3200/eventos.xlsx" 
        "http://localhost:3200/reportes/participantes.pdf"
    )
    
    for i in {1..5}; do
        url=${export_urls[$((RANDOM % ${#export_urls[@]}))]}
        (
            start_time=$(date +%s%N)
            curl -s "$url" > /dev/null 2>&1
            end_time=$(date +%s%N)
            duration=$(( (end_time - start_time) / 1000000 ))
            echo "Export $i: ${duration}ms - $url"
        ) &
        
        sleep 0.5
    done
    
    wait
    echo ""
}

# Test 4: API DNI bajo carga
test_dni_api_load() {
    echo -e "${BLUE}ğŸ†” TEST 4: API DNI BAJO CARGA${NC}"
    echo "============================"
    
    echo "ğŸ“± Simulando mÃºltiples consultas DNI simultÃ¡neas..."
    
    # DNIs de prueba (usa nÃºmeros ficticios)
    test_dnis=(
        "12345678"
        "87654321" 
        "11111111"
        "22222222"
        "33333333"
    )
    
    for i in {1..15}; do
        dni=${test_dnis[$((RANDOM % ${#test_dnis[@]}))]}
        (
            start_time=$(date +%s%N)
            # Ajusta la URL segÃºn tu endpoint de DNI
            curl -s "http://localhost:3200/api/dni/$dni" > /dev/null 2>&1
            end_time=$(date +%s%N)
            duration=$(( (end_time - start_time) / 1000000 ))
            echo "DNI $i ($dni): ${duration}ms"
        ) &
        
        sleep 0.3
    done
    
    wait
    echo ""
}

# Test 5: Carga sostenida (simular dÃ­a completo)
test_sustained_load() {
    echo -e "${BLUE}â° TEST 5: CARGA SOSTENIDA${NC}"
    echo "========================="
    
    echo "ğŸ• Simulando carga continua por 2 minutos..."
    echo "ğŸ’¡ Este test simula uso real durante un dÃ­a completo"
    
    # Archivo para logs
    echo "timestamp,cpu,memory" > /tmp/sustained_load.csv
    
    end_time=$(($(date +%s) + 120)) # 2 minutos
    request_count=0
    
    while [ $(date +%s) -lt $end_time ]; do
        # Request random cada 2-5 segundos
        sleep $((2 + RANDOM % 4))
        
        # Request background
        (curl -s "http://localhost:3200/" > /dev/null 2>&1) &
        
        # Log recursos cada 10 requests
        if [ $((request_count % 10)) -eq 0 ]; then
            timestamp=$(date '+%Y-%m-%d %H:%M:%S')
            stats=$(docker stats incuba-fiis-web --no-stream --format "{{.CPUPerc}},{{.MemUsage}}")
            echo "$timestamp,$stats" >> /tmp/sustained_load.csv
            echo "ğŸ“Š $timestamp - Request #$request_count - Stats: $stats"
        fi
        
        request_count=$((request_count + 1))
    done
    
    echo ""
    echo "ğŸ“Š Carga sostenida completada. Requests totales: $request_count"
    echo "ğŸ“„ Log guardado en: /tmp/sustained_load.csv"
    echo ""
}

# Test 6: Stress test hasta el lÃ­mite
echo "ğŸ’¥ STRESS TEST MEJORADO - MONITOREO DE RECURSOS"
echo "==============================================="
echo ""

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# FunciÃ³n para obtener estadÃ­sticas detalladas
get_detailed_stats() {
    local label="$1"
    
    echo -e "${CYAN}ğŸ“Š [$label] RECURSOS DEL SISTEMA:${NC}"
    echo "=================================="
    
    # Stats de Docker
    DOCKER_STATS=$(docker stats incuba-fiis-web --no-stream --format "{{.CPUPerc}},{{.MemUsage}},{{.MemPerc}},{{.NetIO}},{{.BlockIO}}")
    
    # Separar los valores
    CPU_PERC=$(echo $DOCKER_STATS | cut -d',' -f1)
    MEM_USAGE=$(echo $DOCKER_STATS | cut -d',' -f2)
    MEM_PERC=$(echo $DOCKER_STATS | cut -d',' -f3)
    NET_IO=$(echo $DOCKER_STATS | cut -d',' -f4)
    BLOCK_IO=$(echo $DOCKER_STATS | cut -d',' -f5)
    
    echo -e "ğŸ–¥ï¸  CPU Usage:      ${YELLOW}$CPU_PERC${NC}"
    echo -e "ğŸ’¾ Memory Usage:   ${YELLOW}$MEM_USAGE${NC} (${MEM_PERC})"
    echo -e "ğŸŒ Network I/O:    ${BLUE}$NET_IO${NC}"
    echo -e "ğŸ’¿ Block I/O:      ${BLUE}$BLOCK_IO${NC}"
    
    # Stats adicionales del sistema
    echo ""
    echo -e "${PURPLE}ğŸ”§ DETALLES ADICIONALES:${NC}"
    echo "========================"
    
    # Procesos dentro del contenedor
    PROCESSES=$(docker exec incuba-fiis-web ps aux --no-headers | wc -l)
    echo -e "âš™ï¸  Procesos activos: ${GREEN}$PROCESSES${NC}"
    
    # Conexiones de base de datos
    DB_CONNECTIONS=$(docker exec incuba-fiis-db psql -U cristian -d incuba_fiis_development -t -c "SELECT count(*) FROM pg_stat_activity WHERE datname = 'incuba_fiis_development';" 2>/dev/null | tr -d ' ')
    echo -e "ğŸ—„ï¸  Conexiones DB:   ${GREEN}$DB_CONNECTIONS${NC}"
    
    # Uso de disco
    DISK_USAGE=$(docker exec incuba-fiis-web df -h / | tail -1 | awk '{print $5}')
    echo -e "ğŸ’¾ Uso de disco:    ${GREEN}$DISK_USAGE${NC}"
    
    # Load average del contenedor (si estÃ¡ disponible)
    LOAD_AVG=$(docker exec incuba-fiis-web cat /proc/loadavg 2>/dev/null | awk '{print $1}' || echo "N/A")
    echo -e "ğŸ“ˆ Load Average:    ${GREEN}$LOAD_AVG${NC}"
    
    echo ""
    
    # Guardar en CSV para anÃ¡lisis posterior
    TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')
    echo "$TIMESTAMP,$label,$CPU_PERC,$MEM_USAGE,$MEM_PERC,$NET_IO,$BLOCK_IO,$PROCESSES,$DB_CONNECTIONS,$DISK_USAGE,$LOAD_AVG" >> /tmp/stress_test_detailed.csv
}

# FunciÃ³n para crear header del CSV
create_csv_header() {
    echo "timestamp,test_phase,cpu_percent,memory_usage,memory_percent,network_io,block_io,processes,db_connections,disk_usage,load_average" > /tmp/stress_test_detailed.csv
    echo -e "${GREEN}ğŸ“„ Log detallado creado: /tmp/stress_test_detailed.csv${NC}"
    echo ""
}

# FunciÃ³n de stress test mejorada
enhanced_stress_test() {
    echo -e "${RED}âš ï¸ ADVERTENCIA: Este test intentarÃ¡ sobrecargar el sistema${NC}"
    echo -e "${YELLOW}ğŸ¤” Â¿Continuar? (y/n)${NC}"
    read -r response
    
    if [[ "$response" != "y" ]]; then
        echo "âŒ Test cancelado"
        return
    fi
    
    # Crear CSV header
    create_csv_header
    
    echo -e "${BLUE}ğŸš€ INICIANDO STRESS TEST CON MONITOREO DETALLADO${NC}"
    echo "=============================================="
    echo ""
    
    # Baseline - estado inicial
    echo -e "${CYAN}ğŸ“Š BASELINE - ESTADO INICIAL${NC}"
    get_detailed_stats "BASELINE"
    
    # Array de niveles de concurrencia
    concurrent_levels=(10 25 50 100 200)
    
    for concurrent in "${concurrent_levels[@]}"; do
        echo ""
        echo -e "${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo -e "${YELLOW}ğŸ”¥ PROBANDO CON $concurrent REQUESTS CONCURRENTES${NC}"
        echo -e "${YELLOW}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
        echo ""
        
        # Estado PRE-test
        echo -e "${PURPLE}ğŸ“‹ ANTES DEL TEST $concurrent:${NC}"
        get_detailed_stats "PRE-$concurrent"
        
        echo -e "${BLUE}â±ï¸ Ejecutando $concurrent requests concurrentes...${NC}"
        
        start_time=$(date +%s)
        
        # Ejecutar requests concurrentes
        for i in $(seq 1 $concurrent); do
            curl -s "http://localhost:3200/" > /dev/null 2>&1 &
        done
        
        # Monitoreo DURANTE la ejecuciÃ³n
        echo -e "${GREEN}ğŸ“Š DURANTE LA EJECUCIÃ“N:${NC}"
        sleep 2  # Dar tiempo para que se establezcan las conexiones
        get_detailed_stats "DURING-$concurrent"
        
        # Esperar a que terminen todas las requests
        wait
        
        end_time=$(date +%s)
        duration=$((end_time - start_time))
        
        # Estado POST-test
        echo ""
        echo -e "${GREEN}âœ… $concurrent requests completadas en ${duration}s${NC}"
        echo ""
        echo -e "${PURPLE}ğŸ“‹ DESPUÃ‰S DEL TEST $concurrent:${NC}"
        get_detailed_stats "POST-$concurrent"
        
        # Verificar que el contenedor siga vivo
        if docker ps | grep -q "incuba-fiis-web"; then
            echo -e "${GREEN}âœ… Contenedor estable despuÃ©s de $concurrent requests${NC}"
        else
            echo -e "${RED}âŒ Â¡CONTENEDOR FALLÃ“ con $concurrent requests!${NC}"
            echo -e "${RED}ğŸ’¥ LÃ­mite encontrado: $concurrent requests concurrentes${NC}"
            break
        fi
        
        # Pausa para recuperaciÃ³n
        echo ""
        echo -e "${YELLOW}â³ Esperando 15s para recuperaciÃ³n del sistema...${NC}"
        for i in {15..1}; do
            echo -ne "\râ±ï¸  RecuperaciÃ³n: ${i}s restantes..."
            sleep 1
        done
        echo ""
        
        # Estado despuÃ©s de recuperaciÃ³n
        echo -e "${PURPLE}ğŸ“‹ DESPUÃ‰S DE RECUPERACIÃ“N:${NC}"
        get_detailed_stats "RECOVERY-$concurrent"
        
    done
    
    echo ""
    echo -e "${GREEN}ğŸ STRESS TEST COMPLETADO${NC}"
    echo "========================"
    
    # Estado final del sistema
    echo ""
    echo -e "${CYAN}ğŸ“Š ESTADO FINAL DEL SISTEMA${NC}"
    get_detailed_stats "FINAL"
    
    # Resumen de archivos generados
    echo ""
    echo -e "${GREEN}ğŸ“ ARCHIVOS GENERADOS:${NC}"
    echo "- ğŸ“Š /tmp/stress_test_detailed.csv (log completo)"
    echo ""
    echo -e "${BLUE}ğŸ’¡ Para analizar los resultados:${NC}"
    echo "   cat /tmp/stress_test_detailed.csv | column -t -s','"
    echo ""
}

# FunciÃ³n para mostrar anÃ¡lisis del CSV
analyze_results() {
    if [[ ! -f /tmp/stress_test_detailed.csv ]]; then
        echo -e "${RED}âŒ No se encontrÃ³ archivo de resultados${NC}"
        echo "Ejecuta primero: $0 stress"
        return
    fi
    
    echo -e "${BLUE}ğŸ“ˆ ANÃLISIS DE RESULTADOS DEL STRESS TEST${NC}"
    echo "========================================"
    echo ""
    
    echo -e "${YELLOW}ğŸ“Š TABLA COMPLETA DE RESULTADOS:${NC}"
    cat /tmp/stress_test_detailed.csv | column -t -s','
    echo ""
    
    echo -e "${YELLOW}ğŸ¯ RESUMEN POR FASE:${NC}"
    echo "==================="
    
    # Extraer y mostrar solo las fases principales
    grep -E "(BASELINE|PRE-|DURING-|POST-)" /tmp/stress_test_detailed.csv | while IFS=',' read timestamp phase cpu mem mem_perc net block proc db disk load; do
        echo -e "${GREEN}$phase${NC}: CPU=$cpu, RAM=$mem, Proc=$proc, DB=$db"
    done
    
    echo ""
    echo -e "${PURPLE}ğŸ’¾ Archivo completo disponible en: /tmp/stress_test_detailed.csv${NC}"
}

# FunciÃ³n para limpiar logs anteriores
clean_logs() {
    rm -f /tmp/stress_test_detailed.csv
    echo -e "${GREEN}ğŸ§¹ Logs de stress test limpiados${NC}"
}

# MenÃº principal
case "$1" in
    "stress")
        enhanced_stress_test
        ;;
    "analyze")
        analyze_results
        ;;
    "clean")
        clean_logs
        ;;
    *)
        echo -e "${BLUE}ğŸ’¥ STRESS TEST MEJORADO CON MONITOREO - INCUBAUNAS${NC}"
        echo "=============================================="
        echo ""
        echo "Uso: $0 [opciÃ³n]"
        echo ""
        echo "Opciones disponibles:"
        echo "  stress   - ğŸ’¥ Ejecutar stress test con monitoreo detallado"
        echo "  analyze  - ğŸ“ˆ Analizar resultados del Ãºltimo test"
        echo "  clean    - ğŸ§¹ Limpiar logs anteriores"
        echo ""
        echo "Ejemplos:"
        echo "  $0 stress"
        echo "  $0 analyze"
        echo ""
        echo -e "${YELLOW}ğŸ’¡ El test mostrarÃ¡ CPU, RAM, procesos, y conexiones DB en cada escalÃ³n${NC}"
        echo -e "${YELLOW}ğŸ“Š Todos los datos se guardan en CSV para anÃ¡lisis posterior${NC}"
        ;;
esac


# Reporte final
generate_final_report() {
    echo -e "${BLUE}ğŸ“‹ REPORTE FINAL DE PRUEBAS${NC}"
    echo "=========================="
    
    echo "ğŸ—„ï¸ Estado de la base de datos:"
    docker exec incuba-fiis-db psql -U cristian -d incuba_fiis_development -c "
        SELECT 
            count(*) as conexiones_activas,
            now() as timestamp
        FROM pg_stat_activity 
        WHERE datname = 'incuba_fiis_development';
    " 2>/dev/null
    
    echo ""
    echo "ğŸ³ Estado del contenedor:"
    docker stats incuba-fiis-web --no-stream
    
    echo ""
    echo "ğŸ’¾ Uso de disco:"
    docker exec incuba-fiis-web df -h | head -2
    
    echo ""
    echo -e "${GREEN}âœ… TODAS LAS PRUEBAS COMPLETADAS${NC}"
    echo ""
    echo "ğŸ“Š Archivos generados:"
    echo "- /tmp/sustained_load.csv (carga sostenida)"
    echo "- /tmp/before_load.txt y /tmp/after_load.txt (comparaciÃ³n recursos)"
    echo ""
}

# MenÃº principal
case "$1" in
    "users")
        check_app_running && test_concurrent_users
        ;;
    "forms")
        check_app_running && test_heavy_forms
        ;;
    "exports")
        check_app_running && test_export_stress
        ;;
    "dni")
        check_app_running && test_dni_api_load
        ;;
    "sustained")
        check_app_running && test_sustained_load
        ;;
    "stress")
        check_app_running && test_stress_breaking_point
        ;;
    "report")
        generate_final_report
        ;;
    "all")
        echo -e "${YELLOW}ğŸ¯ EJECUTANDO SUITE COMPLETA DE PRUEBAS${NC}"
        echo "======================================"
        if check_app_running; then
            test_concurrent_users
            test_heavy_forms
            test_export_stress
            test_dni_api_load
            test_sustained_load
            generate_final_report
        fi
        ;;
    *)
        echo -e "${BLUE}ğŸš€ PRUEBAS DE CARGA ESPECÃFICAS - INCUBAUNAS${NC}"
        echo "==========================================="
        echo ""
        echo "Uso: $0 [opciÃ³n]"
        echo ""
        echo "Opciones disponibles:"
        echo "  users      - ğŸ‘¥ Usuarios concurrentes navegando"
        echo "  forms      - ğŸ“ Formularios pesados simultÃ¡neos"
        echo "  exports    - ğŸ“Š Exports masivos (PDF/Excel)"
        echo "  dni        - ğŸ†” API DNI bajo carga"
        echo "  sustained  - â° Carga sostenida (2 minutos)"
        echo "  stress     - ğŸ’¥ Punto de ruptura del sistema"
        echo "  report     - ğŸ“‹ Reporte final del estado"
        echo "  all        - ğŸ¯ Ejecutar todas las pruebas"
        echo ""
        echo "Ejemplos:"
        echo "  $0 users"
        echo "  $0 dni"
        echo "  $0 all"
        echo ""
        echo -e "${YELLOW}ğŸ’¡ RecomendaciÃ³n: Empieza con 'users' y luego 'dni'${NC}"
        ;;
esac